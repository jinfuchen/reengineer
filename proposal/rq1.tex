%\noindent \textbf{Motivation}
%Prior research has conducted empirical studies on performance bugs \cite{Jin:2012}, using the reported performance bugs in issue reports (like JIRA issues). However, there may exist much more performance issues, such as performance regressions, that are not reported as JIRA issues. On the other hand, we evaluate performance of on each code commit instead of depending on JIRA issues. Intuitively, we may uncover instances of performance regressions that are not reported, and are not be able to investigated using the approach of prior studies. Therefore, in this research question, we start off by examining how prevalence are detected performance regression introducing changes. If we could not identify performance regressions in the subject systems, our study would be of less value to the community.

%System performance is closely related to runtime context~\cite{SIGSOFT2007:Goldsmith}. Most of the time code changes can change the runtime context so that it would have a good or bad effect on the software performance.  But It is complicated and difficult to detect the performance regression especially  in large scale system. Therefore, in this research question we want to find the performance impact of the code changes in every consecutive commits between two releases in two open source system \emph{Hadoop} and \emph{RxJava}.

 \textbf{Data and Approach.}
To answer RQ1, we build a logistic regression prediction model for the risk of performance regression introducing change baesd on the commit-level and file-level measures in Table~\ref{tab:measures}. With the approach presented in Section~\ref{sec:case}, we obtain the results of performance evaluation (1 is regression, 0 is not regression) for every test case in our subject systems. In particular, we not only consider a test having performance regression if the response time is statistically significantly longer, but also think over the resource utilization. Sometimes performance regressions may not cause impact on response time but rather cause a higher resource utilization. The high resource utilization, although may not directly impact user experience, may cause extra cost when deploying, operating and maintaining the system, with lower scalability and reliability. 
%For example, systems that are deployed on cloud providers (like Microsoft Azure) may need to choose virtual machines with higher specification for higher resource utilization. Moreover, a software release with a higher memory usage is more prone to crashes from memory leaks. 
Therefore, we also use the physical metrics, i.e., CPU usage, Memory usage, I/O read and I/O write, as measurements of performance regressions. 

To validate how well the model predict performance regression introducing changes, we use two metrics, \emph{precision} and \emph{recall} to measure the model. Â At the same time, to verify the stability of the prediction, we employ 10-fold cross validatoin to test the prediction model.

 \textbf{Results.}
\textbf{Performance regressions are not rare instances.} We find 243 and 91 commits that contain at least one test with performance regression in at least one performance metric for \emph{Hadoop} and \emph{RxJava}, respectively. In total of 1,270 executed tests from \emph{Hadoop} and 7,600 executed tests from \emph{RxJava}, 129 and 1,410 have statistically significantly slower response time with medium or large effect sizes, respectively. When examining the effect sizes of the detected performance regressions, we find that there exist more performance-regression-prone tests with large effect sizes than medium (see Table~\ref{tab:effect}). In addition, we detect more tests with performance regressions in CPU and Memory usage, than other performance metrics. Since CPU and Memory usage both have large impact on the capacity of the software systems, these regressions may impact reliability or financial cost of the software system. 
\begin{table*}[tbh]
	\centering
	\small
	\caption{Results of identifying performance regression introducing changes in different metric classifications. }
	\label{tab:effect}
	\begin{tabular}{|c|r|r|c|r|c|r|c|r|c|r|c|r|}
		\hline
		\multicolumn{13}{|c|}{Total number of tests with performance regressions in different metrics.}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \\ \hline
		\multirow{2}{*}{} & \multirow{2}{*}{\begin{tabular}[c]{@{}r@{}}Total\\ executed tests\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}r@{}}Any \\ metric\end{tabular}} & \multicolumn{2}{c|}{Response time}                                                                                                      & \multicolumn{2}{c|}{CPU}                                                                                                                & \multicolumn{2}{c|}{Memory}                                                                                                             & \multicolumn{2}{c|}{I/O read}                                                                                                           & \multicolumn{2}{c|}{I/O write}                                                                                                          \\ \cline{4-13} 
		&                                                                                 &                                                                        & \begin{tabular}[c]{@{}c@{}}large \\ effect\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}medium \\ effect\end{tabular}} & \begin{tabular}[c]{@{}c@{}}large \\ effect\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}medium \\ effect\end{tabular}} & \begin{tabular}[c]{@{}c@{}}large \\ effect\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}medium \\ effect\end{tabular}} & \begin{tabular}[c]{@{}c@{}}large \\ effect\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}medium \\ effect\end{tabular}} & \begin{tabular}[c]{@{}c@{}}large \\ effect\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}medium \\ effect\end{tabular}} \\ \hline
		Hadoop            & 1,270                                                                           & 338                                                                    & \multicolumn{1}{r|}{87}                                 & 42                                                                            & \multicolumn{1}{r|}{202}                                & 97                                                                            & \multicolumn{1}{r|}{167}                                & 74                                                                            & \multicolumn{1}{r|}{75}                                 & 28                                                                            & \multicolumn{1}{r|}{75}                                 & 17                                                                            \\ \hline
		RxJava            & 7,600                                                                           & 3,100                                                                  & \multicolumn{1}{r|}{745}                                & 665                                                                           & \multicolumn{1}{r|}{659}                                & 487                                                                           & \multicolumn{1}{r|}{919}                                & 489                                                                           & \multicolumn{1}{r|}{657}                                & 449                                                                           & \multicolumn{1}{r|}{38}                                 & 0                                                                             \\ \hline
	\end{tabular}
\end{table*}

 \textbf{Our predictor achieves an average precision of 70.3\% and recall of 82.1\%.} We employ our prediction model into these two systems and the result is shown in Table~\ref{tab:logistic}. We can find that the average precision of 72.5\% in \emph{Hadoop} is higher than the average precision of 68.2\% in \emph{Rxjava}. We infer that there are two reasons: 1) It is the size of the dataset that causes this distinction. The number of tuple is 1120 in \emph{Hadoop} and 7600 in \emph{Rxjava}. But sometimes excessive data can lead to counteractive result, because the prediction model cannot be well fitting to all the data. Redundant data can even result in overfitting, which can significantly decrease the predictive performance.  2) The measures EXP and REXP  are incomplete (missing value) in \emph{Hadoop} and we fill in the missing value by using a global constant. The filled-in value may not be correct and bias the original data.
 
 \textbf{Our predictor performs better in the class of \emph{IO} regression.} In the four classification types, we find that the preditor performs better in the metrics of \jin{IO} in both \emph{Hadoop} (76.3\%) and in  \emph{Rxjava} (70.8\%). This is because unlike \emph{CPU} and \emph{Memory}, which allow dynamic resources allocattion according to different context, \emph{IO} excludes interference from external factors and enables the model to capture more accurate changing patterns.

\begin{table}[]
	\centering
	\footnotesize
	\caption{My caption}
	\label{tab:logistic}
	\begin{tabular}{|c|r|r|r|r|r|r|r|r|}
		\hline
		\multicolumn{1}{|l|}{\multirow{2}{*}{}} & \multicolumn{2}{c|}{Runtime(\%)}                      & \multicolumn{2}{c|}{CPU(\%)}                          & \multicolumn{2}{c|}{Memory(\%)}                       & \multicolumn{2}{c|}{IO(\%)}                           \\ \cline{2-9} 
		\multicolumn{1}{|l|}{}                  & \multicolumn{1}{c|}{pre.} & \multicolumn{1}{c|}{rec.} & \multicolumn{1}{c|}{pre.} & \multicolumn{1}{c|}{rec.} & \multicolumn{1}{c|}{pre.} & \multicolumn{1}{c|}{rec.} & \multicolumn{1}{c|}{pre.} & \multicolumn{1}{c|}{rec.} \\ \hline
		Hadoop                                  & 70.5                      & 83.8                      & 69.1                      & 80.0                      & 73.9                      & 85.8                      & 76.3                      & 77.2                      \\ \hline
		Rxjava                                  & 68.1                      & 82.5                      & 70.0                      & 83.6                      & 63.7                      & 79.8                      & 70.8                      & 84.1                      \\ \hline
		Average                                 & 69.3                      & 83.2                      & 69.6                      & 81.8                      & 68.8                      & 82.8                      & 73.6                      & 80.7                      \\ \hline
	\end{tabular}
\end{table}

\fbox{\parbox{23.5em}{ \emph{We find that performance regression introducing changes are prevalent phenomenon. Logistic regression model can achieve high precision in the prediction of the existence performance regression.}}}
