Techniques that are designed to detect performance regression are done after the system is deployed in performance testing or user environment. However, detected performance regressions are difficult to fix at this late stage. In this paper, we conduct an empirical study on performance regression introducing changes in two open source software \emph{Hadoop} and \emph{RxJava}. We evaluate performance of every commit by executing impacted tests or performance micro-benchmarks. By comparing performance metrics that are measured during the tests or performance micro-benchmarks, we identify and study performance regressions introduced by each commit. In particular, this paper makes the following contributions:
\vspace{-0.2cm}
\begin{itemize} \itemsep 0em
\item To the best of our knowledge, our work is the first to evaluate and to study performance regressions at the commit level. 
\item We propose a statistically rigorous approach to identifying performance regression introducing code changes. Further research can adopt our methodology in studying performance regressions.
\item We find that performance regressions widely exist during development, and often are introduced after bug fixing.
\item We find six root-causes of performance regressions that are introduced by code changes. 12.5\% of the manually examined regressions can be avoided or their performance impact may be reduced.
\end{itemize}
\vspace{-0.2cm}
Our findings call for the need of frequent performance assurance activities (like performance testing) during software development, especially after fixing bugs. Although such activities are often conducted before release~\cite{jacktse}, while developers may find it challenging since many performance issues may be introduced during the release cycle. In addition, developers should resolve performance regressions that are avoidable. For the performance regressions that cannot be avoided, developers should evaluate and be aware of their impact on users. If there exist a large impact on users, strategies, such as allocating more computing resources, may be considered. Finally, in-depth user studies and automated change impact on performance are future directions of this work.  
